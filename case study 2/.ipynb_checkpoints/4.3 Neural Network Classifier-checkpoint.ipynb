{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['traget'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f8b622159b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloandata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./training set/ts_label.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloandata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"traget\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloandata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['traget'] not contained in axis"
     ]
    }
   ],
   "source": [
    "loandata = pd.read_csv(\"./training set/ts_label.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loandata.drop(\"target\", axis = 1)\n",
    "y = loandata[[\"target\"]] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), alpha=1e-4,\\\n",
    "                    solver='sgd', verbose=True, tol=1e-4, random_state=1,\\\n",
    "                    learning_rate_init=.1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 24983.09224419\n",
      "Iteration 2, loss = 24033.78002792\n",
      "Iteration 3, loss = 23111.65420799\n",
      "Iteration 4, loss = 22224.90888993\n",
      "Iteration 5, loss = 21372.18658726\n",
      "Iteration 6, loss = 20552.18189001\n",
      "Iteration 7, loss = 19763.63947641\n",
      "Iteration 8, loss = 19005.35218488\n",
      "Iteration 9, loss = 18276.15917193\n",
      "Iteration 10, loss = 17574.94414850\n",
      "Iteration 11, loss = 16900.63362421\n",
      "Iteration 12, loss = 16252.19533662\n",
      "Iteration 13, loss = 15628.63659244\n",
      "Iteration 14, loss = 15029.00281336\n",
      "Iteration 15, loss = 14452.37603328\n",
      "Iteration 16, loss = 13897.87350837\n",
      "Iteration 17, loss = 13364.64636435\n",
      "Iteration 18, loss = 12851.87830807\n",
      "Iteration 19, loss = 12358.78434641\n",
      "Iteration 20, loss = 11884.60962305\n",
      "Iteration 21, loss = 11428.62822521\n",
      "Iteration 22, loss = 10990.14211817\n",
      "Iteration 23, loss = 10568.48002373\n",
      "Iteration 24, loss = 10162.99644144\n",
      "Iteration 25, loss = 9773.07061815\n",
      "Iteration 26, loss = 9398.10562818\n",
      "Iteration 27, loss = 9037.52746188\n",
      "Iteration 28, loss = 8690.78410022\n",
      "Iteration 29, loss = 8357.34473306\n",
      "Iteration 30, loss = 8036.69889890\n",
      "Iteration 31, loss = 7728.35575116\n",
      "Iteration 32, loss = 7431.84323830\n",
      "Iteration 33, loss = 7146.70744226\n",
      "Iteration 34, loss = 6872.51184798\n",
      "Iteration 35, loss = 6608.83670759\n",
      "Iteration 36, loss = 6355.27837026\n",
      "Iteration 37, loss = 6111.44865955\n",
      "Iteration 38, loss = 5876.97430617\n",
      "Iteration 39, loss = 5651.49636690\n",
      "Iteration 40, loss = 5434.66965995\n",
      "Iteration 41, loss = 5226.16224575\n",
      "Iteration 42, loss = 5025.65493719\n",
      "Iteration 43, loss = 4832.84077388\n",
      "Iteration 44, loss = 4647.42458360\n",
      "Iteration 45, loss = 4469.12252023\n",
      "Iteration 46, loss = 4297.66162806\n",
      "Iteration 47, loss = 4132.77940810\n",
      "Iteration 48, loss = 3974.22346462\n",
      "Iteration 49, loss = 3821.75105886\n",
      "Iteration 50, loss = 3675.12878879\n",
      "Iteration 51, loss = 3534.13216887\n",
      "Iteration 52, loss = 3398.66561042\n",
      "Iteration 53, loss = 3268.28356908\n",
      "Iteration 54, loss = 3142.89696257\n",
      "Iteration 55, loss = 3022.32124253\n",
      "Iteration 56, loss = 2906.37181530\n",
      "Iteration 57, loss = 2794.87118645\n",
      "Iteration 58, loss = 2687.64867073\n",
      "Iteration 59, loss = 2584.54010548\n",
      "Iteration 60, loss = 2485.38764578\n",
      "Iteration 61, loss = 2390.03951589\n",
      "Iteration 62, loss = 2298.34974342\n",
      "Iteration 63, loss = 2210.17796316\n",
      "Iteration 64, loss = 2125.38918978\n",
      "Iteration 65, loss = 2043.85362539\n",
      "Iteration 66, loss = 1965.44645883\n",
      "Iteration 67, loss = 1890.04764598\n",
      "Iteration 68, loss = 1817.54176890\n",
      "Iteration 69, loss = 1747.81782603\n",
      "Iteration 70, loss = 1680.76908492\n",
      "Iteration 71, loss = 1616.29289275\n",
      "Iteration 72, loss = 1554.29055346\n",
      "Iteration 73, loss = 1494.66713823\n",
      "Iteration 74, loss = 1437.33138918\n",
      "Iteration 75, loss = 1382.19551268\n",
      "Iteration 76, loss = 1329.17512022\n",
      "Iteration 77, loss = 1278.18903346\n",
      "Iteration 78, loss = 1229.15919934\n",
      "Iteration 79, loss = 1182.01057125\n",
      "Iteration 80, loss = 1136.67095316\n",
      "Iteration 81, loss = 1093.07094399\n",
      "Iteration 82, loss = 1051.14380210\n",
      "Iteration 83, loss = 1010.82533783\n",
      "Iteration 84, loss = 972.05382570\n",
      "Iteration 85, loss = 934.76991773\n",
      "Iteration 86, loss = 898.91652931\n",
      "Iteration 87, loss = 864.43878947\n",
      "Iteration 88, loss = 831.28389694\n",
      "Iteration 89, loss = 799.40111455\n",
      "Iteration 90, loss = 768.74161422\n",
      "Iteration 91, loss = 739.25846829\n",
      "Iteration 92, loss = 710.90655369\n",
      "Iteration 93, loss = 683.64245358\n",
      "Iteration 94, loss = 657.42442538\n",
      "Iteration 95, loss = 632.21235549\n",
      "Iteration 96, loss = 608.06311591\n",
      "Iteration 97, loss = 584.80268133\n",
      "Iteration 98, loss = 562.37699459\n",
      "Iteration 99, loss = 540.81173636\n",
      "Iteration 100, loss = 520.07390248\n",
      "Iteration 101, loss = 500.13174992\n",
      "Iteration 102, loss = 480.95473448\n",
      "Iteration 103, loss = 462.51352630\n",
      "Iteration 104, loss = 444.77987995\n",
      "Iteration 105, loss = 427.72663018\n",
      "Iteration 106, loss = 411.32769223\n",
      "Iteration 107, loss = 395.55795759\n",
      "Iteration 108, loss = 380.39328378\n",
      "Iteration 109, loss = 365.81045379\n",
      "Iteration 110, loss = 351.78713725\n",
      "Iteration 111, loss = 338.30188492\n",
      "Iteration 112, loss = 325.33403697\n",
      "Iteration 113, loss = 312.86374658\n",
      "Iteration 114, loss = 300.87190822\n",
      "Iteration 115, loss = 289.34018921\n",
      "Iteration 116, loss = 278.25092414\n",
      "Iteration 117, loss = 267.58713565\n",
      "Iteration 118, loss = 257.33249603\n",
      "Iteration 119, loss = 247.47131715\n",
      "Iteration 120, loss = 237.98849058\n",
      "Iteration 121, loss = 228.86950338\n",
      "Iteration 122, loss = 220.10039929\n",
      "Iteration 123, loss = 211.67549607\n",
      "Iteration 124, loss = 203.58550426\n",
      "Iteration 125, loss = 195.78651167\n",
      "Iteration 126, loss = 188.28675376\n",
      "Iteration 127, loss = 181.07475386\n",
      "Iteration 128, loss = 174.13945468\n",
      "Iteration 129, loss = 167.47025526\n",
      "Iteration 130, loss = 161.05694892\n",
      "Iteration 131, loss = 154.88970606\n",
      "Iteration 132, loss = 148.95908661\n",
      "Iteration 133, loss = 143.32920694\n",
      "Iteration 134, loss = 137.90238336\n",
      "Iteration 135, loss = 132.62354363\n",
      "Iteration 136, loss = 127.54724937\n",
      "Iteration 137, loss = 122.66572394\n",
      "Iteration 138, loss = 117.97148746\n",
      "Iteration 139, loss = 113.45736611\n",
      "Iteration 140, loss = 109.11644792\n",
      "Iteration 141, loss = 104.94207589\n",
      "Iteration 142, loss = 100.92787685\n",
      "Iteration 143, loss = 97.06768559\n",
      "Iteration 144, loss = 93.35560931\n",
      "Iteration 145, loss = 89.78596360\n",
      "Iteration 146, loss = 86.35327468\n",
      "Iteration 147, loss = 83.05229149\n",
      "Iteration 148, loss = 79.87796529\n",
      "Iteration 149, loss = 76.82543115\n",
      "Iteration 150, loss = 73.89002055\n",
      "Iteration 151, loss = 71.06723364\n",
      "Iteration 152, loss = 68.35275469\n",
      "Iteration 153, loss = 65.74242852\n",
      "Iteration 154, loss = 63.23225460\n",
      "Iteration 155, loss = 60.81838591\n",
      "Iteration 156, loss = 58.49713758\n",
      "Iteration 157, loss = 56.26495961\n",
      "Iteration 158, loss = 54.11841823\n",
      "Iteration 159, loss = 52.05424088\n",
      "Iteration 160, loss = 50.06925152\n",
      "Iteration 161, loss = 48.16044049\n",
      "Iteration 162, loss = 46.32485313\n",
      "Iteration 163, loss = 44.55969622\n",
      "Iteration 164, loss = 42.86227514\n",
      "Iteration 165, loss = 41.22997200\n",
      "Iteration 166, loss = 39.66030433\n",
      "Iteration 167, loss = 38.15085706\n",
      "Iteration 168, loss = 36.69933176\n",
      "Iteration 169, loss = 35.30348685\n",
      "Iteration 170, loss = 33.96120808\n",
      "Iteration 171, loss = 32.67042764\n",
      "Iteration 172, loss = 31.42916757\n",
      "Iteration 173, loss = 30.23553687\n",
      "Iteration 174, loss = 29.08770865\n",
      "Iteration 175, loss = 27.98392122\n",
      "Iteration 176, loss = 26.92247520\n",
      "Iteration 177, loss = 25.90175755\n",
      "Iteration 178, loss = 24.92021404\n",
      "Iteration 179, loss = 23.97631914\n",
      "Iteration 180, loss = 23.06864560\n",
      "Iteration 181, loss = 22.19579552\n",
      "Iteration 182, loss = 21.35643414\n",
      "Iteration 183, loss = 20.54928255\n",
      "Iteration 184, loss = 19.77309638\n",
      "Iteration 185, loss = 19.02669426\n",
      "Iteration 186, loss = 18.30892613\n",
      "Iteration 187, loss = 17.61869627\n",
      "Iteration 188, loss = 16.95495311\n",
      "Iteration 189, loss = 16.31667221\n",
      "Iteration 190, loss = 15.70288764\n",
      "Iteration 191, loss = 15.11265236\n",
      "Iteration 192, loss = 14.54506139\n",
      "Iteration 193, loss = 13.99925302\n",
      "Iteration 194, loss = 13.47437966\n",
      "Iteration 195, loss = 12.96964049\n",
      "Iteration 196, loss = 12.48427652\n",
      "Iteration 197, loss = 12.01753111\n",
      "Iteration 198, loss = 11.56869669\n",
      "Iteration 199, loss = 11.13708165\n",
      "Iteration 200, loss = 10.72202328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='sgd', tol=0.01, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nURhjjEmRJQpjjDEp+j8WtSJ0CsrbPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111e92cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc\n",
    "false_positive_rate, recall, thresholds = roc_curve(y_test, predictions[:,1])\n",
    "roc_auc=auc(false_positive_rate,recall)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f0461b623500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#score = clf.score(X_test, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy：'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[0;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[0;34m(cv, X, y, classifier)\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1835\u001b[0;31m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1836\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_fold_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_label_splits\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mper_label_cvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_label_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0mlabel_test_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                 \u001b[0;31m# the test split can be too big because we used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;31m# KFold(max(c, self.n_folds), self.n_folds) instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "\n",
    "#score = clf.score(X_test, y_test)\n",
    "scores = cross_val_score(mlp,X_test,y_test,cv=5,scoring='precision')\n",
    "print ('Accuracy：', np.mean(scores), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "confusion_matrix=confusion_matrix(y_test,predictions)\n",
    "plt.matshow(confusion_matrix)\n",
    "plt.title('confusion matrices')\n",
    "plt.colorbar()\n",
    "plt.ylabel('actual')\n",
    "plt.xlabel('predict')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
